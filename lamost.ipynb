{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b6b080b-68d5-4966-b65e-1b7281ae391e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from keras import utils\n",
    "from keras.models import Model \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb19d0a8-7542-455d-a912-4c1486ae0c6a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdulist = fits.open('train_data_01.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "485fc58d-ffaf-4d78-8d0c-91efc43ea202",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "flux = hdulist[0].data\n",
    "labels = hdulist[1].data['label']\n",
    "objid = hdulist[1].data['objid']\n",
    "labels = utils.to_categorical(labels, 3)\n",
    "labels = labels.astype(np.float32)\n",
    "flux = flux.reshape(-1,3000,1).astype(np.float32)\n",
    "\n",
    "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
    "train_flux, train_labels, test_flux, test_labels = flux[train_idx], labels[train_idx], flux[test_idx], labels[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50c33bab-1947-443d-a8bc-495e30511805",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2998</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2996</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1498</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47936</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,067,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_39 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2998\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │            \u001b[38;5;34m64\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_40 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2996\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m1,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_20 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1498\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_19 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47936\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_38 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │     \u001b[38;5;34m3,067,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_39 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,069,795</span> (11.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,069,795\u001b[0m (11.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,069,795</span> (11.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,069,795\u001b[0m (11.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(Conv1D(16, kernel_size=3, activation='relu', input_shape=(3000, 1)))  \n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu'))    \n",
    "model.add(MaxPooling1D(pool_size=2))  \n",
    "#model.add(Dropout(0.1))  \n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64, activation='relu'))  \n",
    "#model.add(Dropout(0.1))  \n",
    "model.add(Dense(3, activation='softmax'))  \n",
    "  \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "82bc167b-f5ef-4ecb-9f33-cdc1f15e0437",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.6783 - loss: 64.1081 - val_accuracy: 0.8580 - val_loss: 2.3213\n",
      "Epoch 2/5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8874 - loss: 2.5862 - val_accuracy: 0.9290 - val_loss: 1.2033\n",
      "Epoch 3/5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.8893 - loss: 5.4643 - val_accuracy: 0.9250 - val_loss: 1.8141\n",
      "Epoch 4/5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9439 - loss: 1.1050 - val_accuracy: 0.9340 - val_loss: 0.4807\n",
      "Epoch 5/5\n",
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9361 - loss: 0.9207 - val_accuracy: 0.9520 - val_loss: 1.4046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fb8a0065240>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "loss='categorical_crossentropy',\n",
    "optimizer='Adam',\n",
    "metrics=['accuracy'])\n",
    "model.fit(train_flux,train_labels, epochs=5, \n",
    "validation_data=(test_flux,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "626024ca-fcca-4f7b-a49d-0db64b7df96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "predicted_labels = model.predict(test_flux)\n",
    "predicted_class = np.argmax(predicted_labels, axis=1)\n",
    "test_class = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64b26e79-bd65-45b1-806f-14034c09f17b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_objid \u001b[38;5;241m=\u001b[39m objid[test_idx]\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m(\u001b[38;5;241m32\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "test_objid = objid[test_idx].astype(np.float(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f626d4b6-4529-4850-a7e6-6516ba7f6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = {'objid':test_objid,'predicted_label':test_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35e56f88-09fb-4404-b426-a9489ba307fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objid': array([4895, 8761, 5714, 4115, 3855, 7367, 1781,  727, 2230, 3263, 5682,\n",
       "        1294, 1097, 5509, 8451, 6070, 1457,  990, 4452, 7951, 6794, 6715,\n",
       "         459, 3922,  685, 7084, 6813, 2487,  944, 2698, 6952, 9652, 3379,\n",
       "        9705, 8460, 1305, 1408, 9545, 9688, 4665, 1607, 3122, 5974, 8212,\n",
       "        6416, 8677, 4094, 6734, 4795, 9514, 7933, 9650,  555,  179, 1634,\n",
       "        3590, 1207, 5594, 9367, 4268, 5344,  336, 1141, 8955, 2591, 5944,\n",
       "        6043, 1730, 7770, 1695, 6103, 5708, 1105, 5345, 3747, 4560, 4464,\n",
       "        1510, 3805, 4481, 6149, 6238, 3204, 7410, 5534, 2399,  833,  493,\n",
       "        6492, 9758, 9116, 9154, 8132, 8402, 4042, 1505, 1058, 7884,  603,\n",
       "        4675, 9497,  304, 8909, 9020, 6614, 1706, 8730, 3607, 4599, 5390,\n",
       "        1081, 1148,  360, 9798, 7245, 2914, 8449, 3546, 5958,  973, 3309,\n",
       "        7510, 1435, 7302, 5371, 2025, 4661, 8781, 8092,  509, 8369, 9753,\n",
       "        5094, 4843, 6235, 4363, 7623, 9745, 8750, 9483, 7049, 4876, 7942,\n",
       "        1747, 7787, 7363, 2774, 1799, 8517, 2530, 1979, 2075, 5772, 7386,\n",
       "        5385, 9468, 2144, 8981,  890, 4389, 5272, 4621, 8942, 5807, 8321,\n",
       "        9195, 6645, 3666,  217, 2798, 2967, 1036, 6159, 9014, 7285, 9260,\n",
       "        3343, 8224, 3018, 6214, 3421, 6323, 6474, 6489, 5293, 2078, 9000,\n",
       "        7567, 8962, 4191, 1543, 2452, 7750, 8634, 1283, 8806, 1599, 1947,\n",
       "        7653, 7921, 4329,  587,   42, 7534, 2362, 9949, 1342, 8583, 5193,\n",
       "        4839, 3500, 5948, 2394, 1866, 4466, 6132, 9715, 6790, 9956, 4693,\n",
       "        7025, 2654, 6082, 5981, 7167, 5215, 8217, 3570, 4676, 3101, 1200,\n",
       "        2055, 2178, 3429, 2256, 6195, 7159, 6299, 6865, 7063, 1357, 7283,\n",
       "        7544,  635, 7577, 8823, 3882, 6519, 5364, 1744, 5717, 6589, 6934,\n",
       "        6363, 7005, 7395, 5404, 1641, 4527,  963, 5387, 5175, 2635, 7814,\n",
       "        5476,  185, 1349,  560,   45, 2566,    8, 9393, 6279,  430, 8696,\n",
       "        2968, 5071, 4349, 8498, 5325, 2087, 6974, 3621, 9646, 9634, 5119,\n",
       "        9814, 1876, 9812, 3635, 1366, 5595, 6419, 1409, 1637, 5617, 9301,\n",
       "        5943, 7735, 2649, 5790, 1111, 6080, 8365,  381, 1012, 3123, 9626,\n",
       "        7530, 7699,  930, 7031, 8235, 8165, 2814, 4502, 9916, 3230, 9615,\n",
       "        6305, 3298,  934, 4671, 7209, 8421, 7594, 4755, 6523, 6881, 6810,\n",
       "        4744, 5578, 4988, 2860,  903, 4259, 7517, 8713, 8469, 6777, 6146,\n",
       "        2174, 7659, 3137, 3146, 4916, 7742,  620, 3586, 7677, 3401, 3957,\n",
       "        1042, 5829, 7917, 1021, 1102, 6725, 6386, 9313,  387, 4562, 8080,\n",
       "         474, 9777, 4039, 1969, 1821, 2546, 8422, 1382, 3431,   67, 4476,\n",
       "        6828, 3135, 8859, 3677, 5639, 1134, 9424, 7836, 7160, 6998, 8260,\n",
       "         565,  482, 1592, 4427, 1865,  166, 8041, 1491, 7827, 2730, 4500,\n",
       "        7969, 4911, 1594, 7572, 9782, 1208, 5086, 1064, 8897, 4854, 2066,\n",
       "        9910, 1759, 3076, 5761, 4312, 3555, 5797, 4425,  486,  294,  364,\n",
       "        8777, 3572, 5935, 3850, 3235, 9508, 9751, 4797, 5457, 2590, 4059,\n",
       "        5556, 5888, 4815, 8034, 4886, 3384,  391, 8259, 1077, 2561, 8331,\n",
       "        5907, 5623, 5762, 1417, 3540, 2026, 6057, 9960, 7602, 2995, 5194,\n",
       "        8006, 7885,  894, 4041, 7763, 9789, 6173, 9892, 6058,  113, 3089,\n",
       "        8633, 3276, 9870, 2018, 2997, 1095, 7088, 6064, 2203, 9293, 1270,\n",
       "        7323, 3989, 7448, 3795, 5463, 2925,  835,  778,  518, 7016, 7669,\n",
       "        5227, 7863, 2771, 4011, 3158, 9005, 7075, 7460,  248, 5414, 5495,\n",
       "        5817, 6570, 2149, 7998, 4936, 3360, 7584, 2683, 5445, 6829, 7198,\n",
       "        2711, 8711, 4698, 6193, 9185, 9780,   19,  859, 6514, 5009,  335,\n",
       "        9214,   87, 8979, 1414, 4165, 8495, 1948,  845, 8923, 5133, 6448,\n",
       "        2206, 4532, 1639, 4694, 4415, 5148, 3275, 1564, 5059, 7056, 7738,\n",
       "        9548,  147, 7721, 6361, 5120, 8556, 4276,  131, 8159, 7573, 4225,\n",
       "        2752,   78, 5739, 3440, 8613, 7570, 6260, 6466, 3554, 3323, 1516,\n",
       "        4337, 1636, 1492, 6880, 4031, 2358, 3478, 6850, 2627, 3451, 5281,\n",
       "        2467, 3530, 4263, 9806,  700, 1654, 2998, 6229, 5237, 4982, 2013,\n",
       "        2155, 4063, 4975, 1844, 3551, 7064, 8062, 7504, 1786,   54,  567,\n",
       "        7421, 9335, 1142, 3520, 2972, 5530, 1745, 2527, 8949,  798, 2020,\n",
       "        6516, 1679, 7914, 4375, 7571, 7882, 3143, 9184, 6011, 4974, 8036,\n",
       "        3838, 7138, 4133, 5632, 8921,  987, 7196, 9324, 5574, 4360, 1621,\n",
       "        3601, 9674, 8388, 8679, 4692, 7250, 4387, 6171, 3793, 3930, 8394,\n",
       "        2148, 4647, 2328, 8162, 8624, 2607, 5716, 5779, 5862, 7944,  557,\n",
       "        3595, 1808, 5038, 2468, 2583, 8686, 1434,  491, 1798, 8068,  771,\n",
       "        9582, 7390, 7760, 6506, 1204, 4279, 2872, 2093, 4273, 3383, 2669,\n",
       "         424,   16, 8073, 5768, 7300, 6446, 3693, 9632, 1149, 6995, 4029,\n",
       "        7876, 3634, 7378, 7535, 8606, 5742, 4825, 6801, 6586, 3284, 5339,\n",
       "        4520, 9911, 4623, 1485, 2701, 4269,  497, 3004, 1784,  965, 6152,\n",
       "        4719, 8359, 2664, 9220, 5411, 9071, 6099, 1623, 2192, 9975, 7169,\n",
       "        8117, 7074, 8704, 2973, 2562, 6121, 6730, 7797, 5942, 3732, 5511,\n",
       "        8521, 7911, 4782, 4574, 1052, 9362, 7147,  510, 4687, 7024, 2651,\n",
       "        7082, 1437, 6795, 6549,  764, 6546,   74, 6543, 3119, 9221,   64,\n",
       "        2490, 1176, 8668, 9903, 6167, 1299, 1085, 5260, 9664, 7765, 8222,\n",
       "        6766, 4050, 2430, 6429, 1627, 2496, 3999, 4680, 9977, 7955, 3760,\n",
       "        1939, 9174, 6911, 2091, 3628, 6788, 7723,  967, 1878, 2400, 7647,\n",
       "        2757, 1555, 5635, 9440, 2670, 3806, 2386, 6048, 8853, 1462, 3869,\n",
       "        3684, 4229, 7104, 5693, 3797, 6432, 3419, 4061, 6367, 8725, 3191,\n",
       "        7611, 3824, 8095, 5405, 6017, 4213, 7246, 1537,  979, 1468, 9992,\n",
       "         949, 2048, 2219, 3070, 3648, 5955, 3133, 5809, 7456, 6200, 1401,\n",
       "        5118, 4351, 4642, 3369, 9589,  460, 4177, 8849, 3232, 2218, 1541,\n",
       "        1897, 2564, 2129, 5573, 5158, 2183, 5835, 5184, 9601, 1911, 6273,\n",
       "        1315, 4242, 4144, 9561, 2717, 9747, 9209, 5661, 6485, 8404, 6993,\n",
       "        8209, 5782, 9033, 5555, 8689, 1065, 5740, 9669, 8076, 4495, 4457,\n",
       "        5013, 1398, 1926, 5122, 4020, 7943, 9564,  946, 3474, 2380, 6976,\n",
       "        6583, 2811,  395, 2949, 5614, 8982, 9640, 1881, 2942, 4594, 9959,\n",
       "        4233,   82, 2123, 7475, 2918, 8508, 3473, 9973, 7870, 5997, 6640,\n",
       "        1475, 5354, 4538, 7181, 6008, 6013, 7464, 8377, 9755, 9499, 4200,\n",
       "        7496, 2931, 4773,  544, 5048, 5021, 9707, 6980,  422, 6287, 2812,\n",
       "        2063,  221, 5099, 9631, 4376, 9546, 8231, 7833, 6337, 6131, 4827,\n",
       "        4215, 7276,  484, 7415, 1324, 8670, 3816, 4881, 7048,  193, 5366,\n",
       "        5111, 8873, 2674, 6534,  334, 3984, 7442, 7427, 3625, 5652, 3251,\n",
       "        1764, 5303, 7362, 8789, 1001, 6559, 3271, 9435, 3780,  365, 4601,\n",
       "        5266, 1393, 6306,  952, 4401, 7251, 5604,   60, 5515,  729, 3891,\n",
       "        4206, 3099, 7687, 9783, 8605,  939, 5597, 2740, 6284, 4890, 3148,\n",
       "        7795, 2685, 5839,  128, 6765,  453, 9067, 5625, 1670, 1493],\n",
       "       dtype='>i8'),\n",
       " 'predicted_label': array([2, 2, 2, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "        0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2,\n",
       "        2, 2, 1, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 2, 2, 1, 2, 0, 0, 2, 0, 2,\n",
       "        2, 0, 2, 0, 2, 2, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 0, 0, 0,\n",
       "        2, 2, 2, 2, 2, 2, 1, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 1, 2, 2,\n",
       "        0, 0, 0, 2, 2, 0, 2, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 2,\n",
       "        2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 2,\n",
       "        2, 2, 0, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 1, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "        0, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 1, 0, 0, 2, 2, 0, 2, 0, 0,\n",
       "        2, 2, 1, 0, 0, 2, 0, 2, 0, 2, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2,\n",
       "        2, 0, 2, 2, 2, 2, 2, 1, 2, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 2, 0, 2,\n",
       "        2, 0, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 2,\n",
       "        2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2, 1, 2, 2, 2,\n",
       "        2, 0, 2, 1, 0, 2, 2, 0, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 2,\n",
       "        2, 2, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 1, 2, 0, 1,\n",
       "        0, 2, 2, 0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 1, 0, 0, 0, 2, 0, 1, 0, 2,\n",
       "        2, 0, 2, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 2,\n",
       "        2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 0, 2, 1, 1, 2, 1, 0, 0, 0,\n",
       "        2, 1, 2, 1, 0, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0, 2, 0, 0, 2,\n",
       "        2, 2, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 0, 0,\n",
       "        2, 0, 2, 0, 0, 0, 2, 2, 0, 2, 0, 2, 1, 2, 1, 2, 0, 0, 0, 0, 2, 2,\n",
       "        2, 2, 0, 1, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2,\n",
       "        0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 1, 2, 0, 0, 2, 2, 2,\n",
       "        0, 2, 0, 2, 1, 2, 0, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 0, 2, 2, 1,\n",
       "        0, 0, 2, 1, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 2, 1, 0, 1, 2, 0, 1, 2,\n",
       "        0, 1, 1, 2, 0, 0, 0, 2, 2, 2, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 0,\n",
       "        2, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2,\n",
       "        1, 2, 1, 2, 2, 0, 2, 2, 2, 1, 0, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2,\n",
       "        0, 2, 0, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0,\n",
       "        2, 2, 2, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 1,\n",
       "        2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 1, 0, 0, 0, 0, 2,\n",
       "        2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 1, 2,\n",
       "        2, 2, 2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 0,\n",
       "        0, 0, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 1, 0, 2, 0, 0, 1, 2, 2, 2, 1,\n",
       "        0, 2, 2, 0, 1, 2, 2, 0, 0, 0, 2, 0, 0, 2, 2, 0, 1, 0, 2, 2, 0, 1,\n",
       "        1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 0, 0, 0, 2,\n",
       "        0, 0, 0, 0, 1, 2, 0, 2, 2, 2, 0, 2, 1, 2, 0, 2, 0, 1, 2, 0, 0, 0,\n",
       "        0, 0, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 1, 1, 2, 0, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 1, 2, 2, 0, 1, 0, 2,\n",
       "        2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 2, 2, 2,\n",
       "        0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0,\n",
       "        0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 2, 0, 2, 1, 2, 2, 0, 2,\n",
       "        2, 2, 0, 2, 0, 1, 2, 2, 1, 2, 0, 0, 2, 2, 2, 0, 2, 0, 2, 1, 0, 2,\n",
       "        2, 0, 2, 0, 1, 2, 2, 0, 2, 0, 1, 1, 0, 2, 2, 2, 0, 2, 0, 2, 2, 0,\n",
       "        2, 0, 2, 0, 2, 0, 2, 2, 0, 0])}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "15ba94b1-59b2-46ff-a65a-e8dd668769c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f89f05-c781-4e54-88e4-c7fbc4a035d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
